<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Narutatsu Ri</title>

  <meta name="author" content="Narutatsu Ri">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/duck.png">
</head>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Narutatsu Ri</name>
                  </p>
                  <p>My name is Edward, and I'm a fifth-year Master's student at Columbia University. I've had the great
                    fortune to be advised by Prof. <a href="http://www.cs.columbia.edu/~kathy/">Kathleen McKeown</a>,
                    <a href="https://www.cs.columbia.edu/~djhsu/">Daniel Hsu</a>, and <a
                      href="https://www.cs.columbia.edu/~verma/">Nakul Verma</a>.
                    <br>
                    I'm supported by the <a href="https://www.recruit-foundation.org/student/li/">Ezoe Memorial
                      Recruit Foundation</a> and formerly by the <a
                      href="https://www.engineering.columbia.edu/academics/undergraduate/egleston-scholars">Egleston
                      Scholars Program</a>.
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/profilephoto.png"><img style="width:70%;max-width:100%" alt="profile photo"
                      src="images/profilephoto.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <div style="line-height: 1.5;">
                    <span style="font-size: 24px;">
                      Some Papers
                    </span>
                    <br>
                    <small>
                      * indicates co-first authorship.
                    </small>
                  </div>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <!-- <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>
                    <a href="">
                      A Probabilistic Model for Analogy Parallelism in High-Dimensional Word Representations
                    </a>
                  </papertitle>
                  <br>
                  <strong>Narutatsu Ri</strong>, Nakul Verma
                  <br>
                  <em>arXiv 2024 (Coming Soon!)</em>
                  <br>
              <em>arXiv 2024</em>
              <br>
              <a href="https://arxiv.org/abs/2409.07072">[paper]</a>
                </td>
              </tr> -->

              <!-- <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>
                    <a href="">
                      A Probabilistic Model for Analogy Parallelism in High-Dimensional Word Representations
                    </a>
                  </papertitle>
                  <br>
                  <strong>Narutatsu Ri</strong>, Nicholas Deas, Kathleen McKeown
                  <br>
                  <em>(Coming Soon!)</em>
                  <br>
                  <a href="https://arxiv.org/abs/2409.07072">[paper]</a>
                </td>
              </tr> -->

              <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>
                    <a href="https://arxiv.org/pdf/2502.04322">
                      Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions
                    </a>
                  </papertitle>
                  <br>
                  Yik Siu Chan*, <strong>Narutatsu Ri*</strong>, Yuxin Xiao*, Marzyeh Ghassemi
                  <br>
                  <em>arXiv 2024</em>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>
                    <a href="https://arxiv.org/abs/2409.07072">
                      Latent Space Interpretation for Stylistic Analysis and Explainable Authorship Attribution
                    </a>
                  </papertitle>
                  <br>Milad Alshomary, <strong>Narutatsu Ri</strong>, Marianna Apidianaki, Ajay Patel, Smaranda Muresan,
                  Kathleen McKeown
                  <br>
                  <em>COLING 2025</em>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>
                    <a href="https://openreview.net/pdf?id=YZM9g0Mi9a">
                      The Effect of Model Capacity on the Emergence of In-Context Learning
                    </a>
                  </papertitle>
                  <br>
                  Berkan Ottlik*, <strong>Narutatsu Ri</strong>*, Daniel Hsu, Clayton Sanford
                  <br>
                  <em>ICLR 2024 (ME-FoMo Workshop) </em>
                </td>
              </tr>


              <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>
                    <a href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/chen24bl/chen24bl.pdf">
                      Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations
                    </a>
                  </papertitle>
                  <br>Yanda Chen, Ruiqi Zhong, <strong>Narutatsu Ri</strong>, Chen Zhao, He He, Jacob Steinhardt, Zhou
                  Yu,
                  Kathleen McKeown
                  <br>
                  <em>ICML 2024 (Spotlight)</em>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>
                    <a href="https://arxiv.org/pdf/2306.08221.pdf">
                      Contrastive Loss is All You Need to Recover Analogies as Parallel Lines
                    </a>
                  </papertitle>
                  <br><strong>Narutatsu Ri</strong>, Fei-Tzin Lee, Nakul Verma
                  <br>
                  <em>ACL 2023 (RepL4NLP Workshop)</em>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>
                    <a href="https://arxiv.org/pdf/2305.12586.pdf">
                      Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design
                      Strategies
                    </a>
                  </papertitle>
                  <br>Linyong Nan, Yilun Zhao, Weijin Zou, <strong>Narutatsu Ri</strong>, Jaesung Tae, Ellen Zhang,
                  Arman Cohan,
                  Dragomir Radev
                  <br>
                  <em>EMNLP 2023 (Findings)</em>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <span style="font-size: 24px;">TA Experience </span>
                  <p>
                  <ul>
                    <li>COMS 4774: Unsupervised Learning</li>
                    <ul>
                      <li>Fall 2024</li>
                    </ul>
                    <li>COMS 4771: Machine Learning</li>
                    <ul>
                      <li>Summer 2022</li>
                      <li>Fall 2022 (Head TA)</li>
                      <li>Spring 2023 (Head TA)</li>
                      <li>Spring 2024 (Head TA)</li>
                      <li>Spring 2025</li>
                    </ul>
                  </ul>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                      <span style="font-size: 24px;">Miscellaneous</span>
                      <ul>
                        <li>[05/15/2023] <a href="data/k_means_survey.pdf">Survey report</a> on \(k\)-means++</li>
                        <li>[04/13/2023] <a href="data/neural_tangent_kernels_notes.pdf">Quick writeup</a> on Neural
                          Tangent
                          Kernels</li>
                        <li>[04/05/2023] <a href="data/model_selection.pdf">Quick writeup</a> on experiments with
                          Decoder-based
                          Transformers and Model Selection </li>

                        <li>[12/19/2022] <a href="data/Normalized_Embeddings_and_Linguistic_Regularity.pdf">Writeup</a>
                          on
                          embeddability of word analogies on the \(n\)-sphere</li>
                        <li>[07/05/2022] <a href="data/2022-7-5-ircn_paper_1.pdf">Presentation</a> on <a
                            href="https://www.biorxiv.org/content/10.1101/2022.06.08.495348v1"> Reconstructing the
                            Cascade of
                            Language Processing in the Brain using the Internal Computations of a Transformer-based
                            Language
                            Model</a> at IRCN (University of Tokyo) </li>
                        <li>[06/13/2022] <a href="data/deep_embedded_clustering.pdf">Quick report</a> on <a
                            href="https://arxiv.org/abs/1511.06335">Deep Embedded Clustering </a></li>
                        <li>[03/17/2021] <a href="data/PU_Learning.pdf">Quick writeup</a> on Positive & Unlabeled (PU)
                          Learning
                        </li>
                        <li>[06/04/2019] <a href="data/JSAI2019_3K4J203.pdf">Paper</a> on 文章中の潜在要素を考慮した対話システム</li>
                        <li>[04/30/2018] <a
                            href="images/robots/13102642_1611791942475943_3945539622257189294_n.jpg">Some</a> <a
                            href="images/robots/IMG_0212.JPG">robots</a> <a href="images/robots/IMG_7258.JPG">I've</a>
                          <a href="images/robots/IMG_8384.JPG">built</a> <a href="images/robots/IMG_9528.jpeg">in</a>
                          the past
                        </li>
                      </ul>
                    </td>
                  </tr>
                </tbody>
              </table>
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>

                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr>
                        <td style="padding:0px">
                          <br>
                          <p style="text-align:right;font-size:small;">
                            Website design taken from <a href="https://github.com/jonbarron/jonbarron_website">Jon
                              Barron. </a>
                          </p>
                        </td>
                      </tr>
                    </tbody>
                  </table>
        </td>
      </tr>
  </table>
</body>

</html>